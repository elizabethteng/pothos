{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "import lhsmdu\n",
    "import pdspy.modeling as modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"Tstar\",\"logLstar\",\"logMdisk\",\"logRdisk\",\"h0\",\"logRin\",\\\n",
    "          \"gamma\",\"beta\",\"logMenv\",\"logRenv\",\"fcav\",\"ksi\",\"logamax\",\"p\",\"incl\"]\n",
    "ranges = [[3000.,5000.], [-1,3.],[-8.,-2.], [0.,3.],[0.01,0.5], [-1.,2.5], [0.0,1.999], \\\n",
    "          [0.5,2.0],[-8.,-2.],[2.5,4.], [0.,1.], [0.5,1.5], [0.,5.], [2.5,4.5], [0.,90.]]\n",
    "\n",
    "new_param_names = [\"T_star\",\"logL_star\",\"logM_disk\",\"logR_disk\",\"h_0\",\"logR_in\",\\\n",
    "               \"gamma_trans\",\"bi_x\",\"logM_env_trans\",\"logR_env\",\"f_cav\",\"ksi\",\"loga_max\",\"p\",\"bi_y\"]\n",
    "new_ranges = [[3000.,5000.], [-1,3.],[-8.,-2.], [0.,3.],[0.01,0.5], [-1.,2.5], [np.log10(0.101),np.log10(2.1)], \\\n",
    "          [0,2],[np.log10(0.5),np.log10(6.5)],[2.5,4.], [0.,1.], [0.5,1.5], [0.,5.], [2.5,4.5], [-1.25,0.75]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates coordinates for LHC of \"n_models\" models, distributed across \"ranges\"\n",
    "# returns coordinates by axis and by point.\n",
    "\n",
    "def generate_lhc(n_models, ranges): \n",
    "    dimensions = len(ranges)\n",
    "    ndsample_01 = np.array(lhsmdu.sample(dimensions, n_models))\n",
    "    scale = []\n",
    "    offset = []\n",
    "    for i in range(len(ranges)):\n",
    "        scale.append(ranges[i][1]-ranges[i][0])\n",
    "        offset.append(ranges[i][0])\n",
    "\n",
    "    ndsample_toscale = ndsample_01 * np.array(scale)[:,np.newaxis] \n",
    "    ndsample_inplace = ndsample_toscale + np.array(offset)[:,np.newaxis]\n",
    "\n",
    "    sample_byaxis = ndsample_inplace\n",
    "    sample_bypoint = np.transpose(sample_byaxis)\n",
    "    \n",
    "    return (sample_byaxis, sample_bypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig_to_trans(pars):\n",
    "    gamma=pars[6]\n",
    "    logM_env=pars[8]\n",
    "    beta=pars[7]\n",
    "    incl=pars[14]\n",
    "    \n",
    "    pars[6]=np.log10(2.1-1*gamma)\n",
    "    pars[8]=np.log10(-1.5-1*logM_env)\n",
    "    \n",
    "    s=np.sin(0.7)\n",
    "    c=np.cos(0.7)\n",
    "    \n",
    "    theta=0.7\n",
    "    pars[7]=1-np.cos(((beta*c) + (incl*s/60)-.5)*np.pi/2)\n",
    "    pars[14]=(-beta*s) + (incl*c/60)\n",
    "    return pars\n",
    "\n",
    "def trans_to_orig(pars):\n",
    "    gamma_trans=pars[6]\n",
    "    logM_env_trans=pars[8]\n",
    "    bi_x=pars[7]\n",
    "    bi_y=pars[14]\n",
    "    \n",
    "    pars[6]=2.1 - 10**gamma_trans\n",
    "    pars[8]=-1.5 - 10**logM_env_trans\n",
    "    \n",
    "    s=np.sin(0.7)\n",
    "    c=np.cos(0.7)\n",
    "    \n",
    "    pars[7]=round((1/(c+(s**2/c)))*((2/np.pi)*np.arccos(1-bi_x)+0.5-(s/c)*bi_y),14)\n",
    "    pars[14]=round((60*s)*((2/np.pi)*np.arccos(1-bi_x)+0.5+(c/s)*bi_y),14)\n",
    "    return pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223.9470753669739\n"
     ]
    }
   ],
   "source": [
    "#t0=time()\n",
    "#trans_sample=generate_lhc(400,[[0,2],[-1.25,0.75]])\n",
    "#t1=time()-t0\n",
    "#print(t1)\n",
    "\n",
    "#with open('./transsample_byaxis.txt', 'wb') as fp:\n",
    "#    pickle.dump(trans_sample[0], fp)\n",
    "\n",
    "#origsample_byaxis=generate_lhc(400,[[0.5,2],[0,90]])[0]\n",
    "#with open('./origsample_byaxis.txt', 'wb') as fp:\n",
    "#    pickle.dump(origsample_byaxis, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./transsample_byaxis.txt', 'rb') as fp:\n",
    "    transsample_byaxis = pickle.load(fp)\n",
    "with open ('./origsample_byaxis.txt', 'rb') as fp:\n",
    "    origsample_byaxis = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ranges(ranges,scale_factors):\n",
    "    new_ranges=[]\n",
    "    for i in range(len(ranges)):\n",
    "        if scale_factors[i]==1:\n",
    "            new_ranges.append(ranges[i])\n",
    "        else:\n",
    "            a=ranges[i][0]\n",
    "            b=ranges[i][1]\n",
    "            s=scale_factors[i]\n",
    "            new_ranges.append([(a-(s/2-0.5)*(b-a)),(b+(s/2-0.5)*(b-a))])\n",
    "    return (new_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777600.0\n"
     ]
    }
   ],
   "source": [
    "scaleup=[4,1.5,1,2,1,1,1,1,1,3,2,1,1,1.8,1]\n",
    "inflated_ranges=generate_ranges(new_ranges,scaleup)\n",
    "\n",
    "totalscale=1.5 # for beta/incl cut\n",
    "for i in range(len(scaleup)):\n",
    "    totalscale=totalscale*scaleup[i]\n",
    "\n",
    "print(totalscale*4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./etgrid/etgrid_coords_byaxis_trans.txt', 'rb') as fp:\n",
    "    coords_byaxis = pickle.load(fp)\n",
    "with open ('./etgrid/etgrid_coords_bypoint_trans.txt', 'rb') as fp:\n",
    "    coords_bypoint = pickle.load(fp)\n",
    "    \n",
    "with open('./etgrid/etgrid_coords_byaxis_orig.txt', 'wb') as fp:\n",
    "    pickle.dump(coords_byaxis_orig, fp)\n",
    "with open('./etgrid/etgrid_coords_bypoint_orig.txt', 'wb') as fp:\n",
    "    pickle.dump(coords_bypoint_orig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=np.load(\"./gmd/dictionary.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE import lhs\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranges = [[3000.,5000.], [-1,3.],[-8.,-2.], [0.,3.],[0.01,0.5], [-1.,2.5], [np.log10(0.101),np.log10(2.1)], \\\n",
    "          [0,2],[np.log10(0.5),np.log10(6.5)],[2.5,4.], [0.,1.], [0.5,1.5], [0.,5.], [2.5,4.5], [-1.25,0.75]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ranges(ranges,scale_factors):\n",
    "    new_ranges=[]\n",
    "    for i in range(len(ranges)):\n",
    "        if scale_factors[i]==1:\n",
    "            new_ranges.append(ranges[i])\n",
    "        else:\n",
    "            a=ranges[i][0]\n",
    "            b=ranges[i][1]\n",
    "            s=scale_factors[i]\n",
    "            new_ranges.append([(a-(s/2-0.5)*(b-a)),(b+(s/2-0.5)*(b-a))])\n",
    "    return (new_ranges)\n",
    "\n",
    "scaleup=[4,1.5,1,2,1,1,1,1,1,3,2,1,1,1.8,1]\n",
    "inflated_ranges=generate_ranges(new_ranges,scaleup)\n",
    "\n",
    "totalscale=1.5 # for beta/incl cut\n",
    "for i in range(len(scaleup)):\n",
    "    totalscale=totalscale*scaleup[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample successfully drawn\n"
     ]
    }
   ],
   "source": [
    "n_models=int(4000*totalscale)\n",
    "ranges=inflated_ranges\n",
    "\n",
    "dimensions = len(ranges)\n",
    "ndsample_01 = np.array(lhs(dimensions, samples=n_models))\n",
    "print(\"sample successfully drawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = []\n",
    "offset = []\n",
    "for i in range(len(ranges)):\n",
    "    scale.append(ranges[i][1]-ranges[i][0])\n",
    "    offset.append(ranges[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndsample_toscale = ndsample_01 * np.array(scale)\n",
    "ndsample_inplace = ndsample_toscale + np.array(offset)\n",
    "\n",
    "sample_bypoint = ndsample_inplace\n",
    "sample_byaxis = np.transpose(sample_bypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./etgrid/raw_coords_byaxis.txt', 'wb') as fp:\n",
    "    pickle.dump(sample_byaxis, fp)\n",
    "with open('./etgrid/raw_coords_bypoint.txt', 'wb') as fp:\n",
    "    pickle.dump(sample_bypoint, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import george\n",
    "from george import kernels\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"T_star\",\"logL_star\",\"logM_disk\",\"logR_disk\",\"h_0\",\"logR_in\",\\\n",
    "          \"gamma\",\"beta\",\"logM_env\",\"logR_env\",\"f_cav\",\"ksi\",\"loga_max\",\"p\",\"incl\"]\n",
    "\n",
    "ranges = [[3000.,5000.], [-1,3.],[-8.,-2.], [0.,3.],[0.01,0.5],[-1.,2.5],[0.0,2.0],\\\n",
    "        [0.5,2.0],[-8.,-2.],[2.5,4.], [0.,1.], [0.5,1.5],[0.,5.],[2.5,4.5],[0.,90.]]\n",
    "steps=[]\n",
    "bases=[]\n",
    "for i in range(len(ranges)):\n",
    "    steps.append(np.linspace(ranges[i][0],ranges[i][1],11))\n",
    "    bases.append(steps[i][5])\n",
    "\n",
    "# get all model data\n",
    "with open ('../grid_metadata/corefull.txt', 'rb') as fp:\n",
    "    core= pickle.load(fp)[100:500]\n",
    "with open ('../grid_metadata/cubefull.txt', 'rb') as fp:\n",
    "    cube = np.array(pickle.load(fp))[:,100:500]\n",
    "with open ('../grid_metadata/cubefull.txt', 'rb') as fp:\n",
    "    nancube = np.array(pickle.load(fp))[:,100:500]\n",
    "    \n",
    "# x values (wavelengths) - 500 values, in normal space\n",
    "with open ('../grid_metadata/xvals.txt', 'rb') as fp:\n",
    "    xvals = pickle.load(fp)[100:500]\n",
    "\n",
    "# fix -infs: powerlaw cutoff\n",
    "for i in range(len(cube)):\n",
    "    if -np.inf in cube[i]:\n",
    "        a = cube[i].tolist()\n",
    "        a.reverse()\n",
    "        ind = len(a)-a.index(-np.inf)\n",
    "        x1 = xvals[ind]\n",
    "        y1 = cube[i][ind]\n",
    "        for j in range(ind):\n",
    "            cube[i][j]=(100*(np.log10(xvals[j]/x1)))+y1\n",
    "            \n",
    "# nan cutoff for means            \n",
    "nancube[nancube<-20]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.365s\n"
     ]
    }
   ],
   "source": [
    "# subtracting from the seds each sample mean\n",
    "seds_msub = cube - np.nanmean(nancube,axis=1)[:,np.newaxis]\n",
    "\n",
    "t0 = time.time()\n",
    "pca = PCA(n_components=40).fit(seds_msub)\n",
    "print(\"done in %0.3fs\" % (time.time() - t0))\n",
    "\n",
    "eigenseds=np.array(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slices - read in filenames and logspace flux values\n",
    "with open ('../grid_metadata/slicenames.txt', 'rb') as fp:\n",
    "    slicenames = pickle.load(fp)\n",
    "with open ('../grid_metadata/slicevals.txt', 'rb') as fp:\n",
    "    slicevals = pickle.load(fp)[:,:,100:500]\n",
    "with open ('../grid_metadata/slicevals.txt', 'rb') as fp:\n",
    "    nanslicevals = pickle.load(fp)[:,:,100:500]\n",
    "\n",
    "# fix -infs: powerlaw cutoff\n",
    "for i in range(len(slicevals)):\n",
    "    for j in range(len(slicevals[i])):\n",
    "        if -np.inf in slicevals[i][j]:\n",
    "            a = slicevals[i][j].tolist()\n",
    "            a.reverse()\n",
    "            ind = len(a)-a.index(-np.inf)\n",
    "            x1 = xvals[ind]\n",
    "            y1 = slicevals[i][j][ind]\n",
    "            for m in range(ind):\n",
    "                slicevals[i][j][m]=(100*(np.log10(xvals[m]/x1)))+y1\n",
    "                \n",
    "nanslicevals[nanslicevals<-20]=np.nan\n",
    "\n",
    "slice_seds_msub = slicevals - np.nanmean(nanslicevals,axis=2)[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitdata=[]\n",
    "\n",
    "for i in range(len(param_names)):\n",
    "    fitdata.append([])\n",
    "for i in range(len(param_names)):\n",
    "    for j in range(11):\n",
    "        modeldata=[]\n",
    "        paramval=steps[i][j]\n",
    "        coeffs=pca.transform(slice_seds_msub[i][j].reshape(1,-1))\n",
    "        modeldata.append(paramval)\n",
    "        for k in range(10):\n",
    "            modeldata.append(coeffs[0][k])\n",
    "        fitdata[i].append(modeldata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramvals=[]\n",
    "weights=[]\n",
    "for param in range(15):\n",
    "    pl=[]\n",
    "    wl=[]\n",
    "    for model in range(11):\n",
    "        pl.append(fitdata[param][model][0])\n",
    "    paramvals.append(pl)\n",
    "    \n",
    "    for w in range(10):\n",
    "        wsl=[]\n",
    "        for model in range(11):\n",
    "            wsl.append(fitdata[param][model][w+1])\n",
    "        wl.append(wsl)\n",
    "    weights.append(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"slice_params.npy\",paramvals)\n",
    "np.save(\"slice_weights.npy\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
